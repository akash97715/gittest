ias_chat_model = IAS_ChatModel(
    engine="gpt-4",
    temperature=0.7,
    max_tokens=150,
    user_query="Your user query here",
    min_response_token=10,
    system_message=None,
    client_id="your_client_id",
    x_vsl_client_id="your_x_vsl_client_id",
    bearer_token="your_bearer_token",
    context=[],
    openai_proxy=None,
    request_timeout=None,
    max_retries=2,
    streaming=False,
    n=1,
    tiktoken_model_name=None,
    default_headers=None,
    default_query=None,
    http_client=None,
    http_async_client=None
)
